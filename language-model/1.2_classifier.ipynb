{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.2_classifier.ipynb","version":"0.3.2","provenance":[{"file_id":"15kL7ZxocIQ5R58-WJTkv4TZp84uKqssQ","timestamp":1537187879456},{"file_id":"https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb","timestamp":1536846729496}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"zqpLcL8WkuCY","colab_type":"text"},"cell_type":"markdown","source":["# Whose Line Is It Anyway?\n","Given a sentence from a State of the Nation address, can we correctly predict which president said it?"]},{"metadata":{"id":"ahXVraYZjmY8","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from keras.preprocessing import sequence\n","from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Activation, Bidirectional, RepeatVector, Input\n","from keras.optimizers import Adam\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fzQ03mS3A485","colab_type":"text"},"cell_type":"markdown","source":["## Reading In and Overview of Data\n","\n","The data that is read in using the terminal lines above has been through some rigorous pre-processing. The resulting dataset consists of rows of individual sentences in a column called **'text'**, with a corresponding integer value between 0 and 5 in the **'labels'** column which refers to the president who spoke that sentence.\n","\n","The label-to-president mapping is as follows:\n","\n","- 0: De Klerk\n","- 1: Mandela\n","- 2: Mbeki\n","- 3: Motlanthe\n","- 4: Zuma\n","- 5: Ramaphosa"]},{"metadata":{"id":"blv8N_zlaHRu","colab_type":"code","colab":{}},"cell_type":"code","source":["# read text data\n","df = pd.read_csv('https://raw.githubusercontent.com/James-Leslie/president-speech-classifier/master/data/model_input.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EyfZ3E3DNWU5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"a83632c8-3616-40a8-960d-ba0a2cbd0f18","executionInfo":{"status":"ok","timestamp":1537472986057,"user_tz":-120,"elapsed":921,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# show some of the data\n","df.head(5)"],"execution_count":144,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>mr speaker</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>this parliament has convened to adopt importan...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>the fact that we have done so in the midst of ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>it is an indication of the importance which w...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>if we wish to have a peaceful and stable futur...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   labels                                               text\n","0       0                                         mr speaker\n","1       0  this parliament has convened to adopt importan...\n","2       0  the fact that we have done so in the midst of ...\n","3       0   it is an indication of the importance which w...\n","4       0  if we wish to have a peaceful and stable futur..."]},"metadata":{"tags":[]},"execution_count":144}]},{"metadata":{"id":"sa9K87rMvwtL","colab_type":"text"},"cell_type":"markdown","source":["### Number of Lines of Text per President\n","\n","After the pre-processing, each row of the dataset contains roughly one sentence as spoken by a president. We take a look at the distribution of sentences per president to get an idea of the inherent class balances (or imbalances)."]},{"metadata":{"id":"8ms1HDSKvhmF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"7e436b4a-f9f5-4b54-a29e-64e636b46778","executionInfo":{"status":"ok","timestamp":1537472987932,"user_tz":-120,"elapsed":900,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["df['labels'].value_counts()"],"execution_count":145,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    3145\n","2    3074\n","1    1785\n","3     306\n","5     275\n","0     105\n","Name: labels, dtype: int64"]},"metadata":{"tags":[]},"execution_count":145}]},{"metadata":{"id":"NkxU-bgRENtj","colab_type":"text"},"cell_type":"markdown","source":["Evidently, Zuma and Mbeki have by far the majority of sentences. There is a serious class imbalance, one which calls for some class rebalancing before any classification model is trained. We will revisit the class imbalance problem in a little while, but first we'll need to split the data into train and test sets."]},{"metadata":{"id":"KZC6-cPjyogJ","colab_type":"text"},"cell_type":"markdown","source":["## Train/Test Split\n","\n","It is important that before we do any class balancing, the data be split into train and test sets. The reason for this is that if we decided to use some method of resampling data from the minority classes in order to simulate a more balanced distribution, and only then split it into train and test sets, we might see duplicates of some observations appearing in both the train and test sets.\n","\n","Clearly, this will affect the performance of the model: if it is trained on an observation and then shown that observation again during validation, we are not performing a true test of unseen data. The model will have learnt by heart what to classify that observation as.\n","\n","We make use of the **`train_test_split`** function from **`scikitlearn`**."]},{"metadata":{"id":"Qx8w7tPcyrew","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train, test, _, _ = train_test_split(df[['labels', 'text']],\n","                                     df['labels'],\n","                                     test_size=0.15,\n","                                     random_state=85)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RQAETcBBISBX","colab_type":"text"},"cell_type":"markdown","source":["## Class Imbalance"]},{"metadata":{"id":"kll8JpzrJcSP","colab_type":"text"},"cell_type":"markdown","source":["There are various means to balance classes for classification problems. One of those means is to downsample the majority class, ie, when creating training data for the model, feed it some subset of all the observations in the majority class. The problem with this method is that you tend to throw away valuable data in the observations that are not sampled.\n","\n","A nice alternative is upsampling the minority class, ie, repeating some observations from that class to simulate a greater dataset. The problem with this method is that the model tends to overfit to the training data as it is fed duplicate observations during training.\n","\n","A third method is to create new, synthetic observations based on the observations that exist in the minority class. One way to do this is with k-nearest neighbours: find, say, the 3 nearest neighbours to some point in the featurespace, and generate a new point based on the average of those 3 others. This is typically a more trivial problem when the features are all numeric. However, this is tricky to do with text data while still maintaining the order and adjacency of words in sequence.\n","\n","As such, we developed a synthetic text data generator of our own. The basic process of the synthetic data generation is as follows:\n","\n","1.  Using term frequency-inverse document frequency, create a frequency matrix of n-grams from the sentences in the minority class, where n is a specified as a range of integers by the modeller.\n","2. Create a list of relative frequencies of these n-grams by summing the rows of the frequency matrix in a column-wise fashion.\n","3. Divide this list by the sum of the list. This effectively turns the list of frequencies into a list of probabilities with which each n-gram appears in in the sentence data.\n","4. Retrieve the list of n-grams from the column names of the frequency table.\n","5. We now have a list of n-grams, or mini-sentences, and a corresponding list of the probabilities of finding each of those n-grams in the original text data.\n","6. We then loop a user-specified number of times - this value should correspond with the number of new sentences required.\n","7. Within each cycle, we randomly sample, without replacement, three n-grams from the list in step 5. These three n-grams are concatenated to form a new term.\n","7. These terms are the new sentences, and we append them to the original data. The number of samples is an argument to be specified by the modeller, and should be chosen such that the total of synthetic and original observations roughly equals the number of observations in the majority class.\n","\n","### Possible Problems with this Approach\n","\n","It did occur to us during the design of this class balancing method that when concatenating various n-grams, any two n-grams placed adjacent to one another would create a bi-gram at the interface of these two n-grams.\n","\n","We decided that an important validation to implement given more time to work on the project, would be to check the bi-gram created at the interface of two n-grams against a list of all existing bi-grams in the corpus. Reason being, it would be important to ensure that we are not placing words next to each other that the president in question has never actually said, and would not be likely to ever say.\n","\n","We stopped short of implementing a validation like this, because we decided that even if the new bi-gram did exist elsewhere in the corpus, the second-last word in the first n-gram, and the second word in the second n-gram would also contribute to new tri- and quad-grams, and so on and so forth. Recursively checking each of these to see if they exist in the corpus would be very slow, and probably limit the volume of synthetic data we would be able to generate."]},{"metadata":{"id":"YUVnMvT-0Qq8","colab_type":"code","colab":{}},"cell_type":"code","source":["def synthesize(original, target, n_gram_range):\n","    \n","    # create the tfidf vectoriser object\n","    tvec = TfidfVectorizer(stop_words='english',\n","                           ngram_range=n_gram_range,\n","                           token_pattern = r'(?u)\\S\\S+')\n","    \n","    # fit the tfidf vectoriser object to the sentence data for deKlerk\n","    tfidf = tvec.fit_transform(original['text'])\n","    \n","    # create dataframe of all n-grams and their weightings\n","    grams = pd.DataFrame(tfidf.todense(), columns=tvec.get_feature_names())\n","    \n","    # sum the dataframe column-wise and divide by the sum of the resulting row\n","    # this gives a vector of weights which sum to 1\n","    probs = grams.sum(axis=0)/sum(grams.sum(axis=0))\n","    \n","    # vector of n-grams from which to sample\n","    terms = list(tvec.get_feature_names())\n","    \n","    # empty vector for new sentence data\n","    new_list = []\n","    \n","    # create loop to run target number of times and concatenate 3 n-grams\n","    for i in range(target):\n","      # randomly find 3 different n-grams\n","      three_n_grams = np.random.choice(terms, 3, replace=False, p=probs)\n","      \n","      # create single sentence using three terms together\n","      new_term = ' '.join(three_n_grams)\n","      \n","      new_list.append(new_term)\n","      \n","    \n","    \n","    # set labels column of new data equal to that of input\n","    new_list = pd.DataFrame(new_list, columns=['text'])\n","    \n","    new_list['labels'] = original['labels'].values[0]\n","    \n","    return new_list"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UcTEtxFzROHx","colab_type":"text"},"cell_type":"markdown","source":["### History of Class Balancing Within This Project\n","\n","Prior to implementing the method of upsampling using synthetic data as detailed above, we trialled two other alternative methods of balancing the classes.\n","\n","#### Library: imbalanced-learn\n","\n","The first made use of a Python library by the name of **`imbalanced-learn`**, which contains methods to do various types of up- and down-sampling for your dataset.\n","\n","For reasons detailed above, we did not bother to do standard up- and down-sampling of minority and majority classes, respectively. `imblearn` does, however, contain a method called `smote` (Synthetic Minority Oversampling Technique), which uses k-nearest neighbours to create new observations based on existing observations within the feature space. The issue with this approach and with the `imblearn` library in general was that it required data to be vectorised before it could be meddled with. In the context of our speech data, this meant creating a bag of words model where each word's occurence in a sentence/document is represented by a number in a sparse matrix.\n","\n","Clearly, vectorising a sentence absents the order and adjacency inherent in that sentence, which we thought would be very important in helping a model determine patterns in speech. As such, we could not use any of the methods in the `imblearn` library.\n","\n","#### Synthesizing Basic Sentences\n","\n","The next thing we tried was the basis for the `synthesize` function in the code block above. The basic outline of the process was as follows:\n","\n","1. Generate a list of n-grams from the text data. The n-value is a range specified by the user.\n","2. Sum the frequency of each n-gram for all documents to obtain overall frequency in the corpus.\n","3. Randomly sample from the list of n-grams, in the proportion that they occur in the corpus. i.e.: using as the sampling distribution the frequencies summed in step 2.\n","4. Each n-gram sampled is now a new sentence that is appended to the original dataset.\n","\n","This process produced a list of terms of a few words each which were all exceprts of sentences said by the president in question. It was an effective way of generating data for the minority classes without the risk of having duplicate observations. It was a natural extension of this idea to concatenate multiple of these n-grams into a new sentence, which is what we ultimately included in the model, above.\n","\n","#### Classification Results\n","\n","To our dismay, there appeared to be no synthetic data generation that we could do with any of these methods which improved the test accuracy of our neural network classifier.\n","\n","Recall that we carry out the train/test split _before_ synthesizing new data. This is important to ensure the test set contains only original sentences as spoken by the president. We would then carry out synthetic data generation using the training set only, and go on to train the model with that part-original, part-synthetic data.\n","\n","What we found was that regardless of the size of the n-grams selected by the user for the synthetic data, and regardless of the model architecture, and regardless of whether the classes were balanced or not, the test accuracy would not exceed around 61%. Initially it was baffling, but the conclusion that Kieran has come to is that the two classes with the most observations, Zuma and Mbeki, tend to dominate the accuracy of the model.\n","\n","In other words, because the sentences by Zuma and Mbeki make up around 70% of the total sentences in the data set, the model appeared to be getting an accuracy of up to 80% for these two classes, with the remainder of the accuracy coming from a handful of correct classifications in the other four classes.\n","\n","An intuitive conclusion would be to say that the synthetic data generation made zero difference, but we believe it more likely to be the fact that there is so little data for the minority classes like deKlerk and Ramaphosa, that the variety in their sentences was not significant enough anyway. They simply did not have enough unique sentences or phrases to be classified correctly and repeatedly."]},{"metadata":{"id":"-RIsDQ2of6XC","colab_type":"text"},"cell_type":"markdown","source":["We now have a function which can be called to generate new synthetic data for minority classes for the purposes of balancing them with the majority ones. We may as well bring the number of observations in all the classes to match the number in the most common class.\n","\n","After splitting into train and test sets, the distribitions are as follows:"]},{"metadata":{"id":"cSlzCD58gtDt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":389},"outputId":"be727181-dcad-4346-a451-8a5f167c6e0b","executionInfo":{"status":"ok","timestamp":1537472993539,"user_tz":-120,"elapsed":1172,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["train['labels'].value_counts().plot(kind='bar')\n","plt.xlabel('Class')\n","plt.ylabel('Observations')\n","plt.title('Observations per Class')"],"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5,1,'Observations per Class')"]},"metadata":{"tags":[]},"execution_count":148},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfgAAAFjCAYAAADRiRn/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQBQ8AAAG+n/nllQ6jvfqHQAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f7bd7ebc9e8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"GTo1PzydhLwg","colab_type":"text"},"cell_type":"markdown","source":["Clearly, we'll need to bring up the number of samples for all the classes except that with label 4 (Zuma). In order to do that we create separate datasets containing the training observations for each president."]},{"metadata":{"id":"tsjLRJkLwPQR","colab_type":"code","colab":{}},"cell_type":"code","source":["# create separate training sets for each of the unbalanced classes\n","fwdk_train = train[train['labels']==0]\n","mand_train = train[train['labels']==1]\n","mbe_train = train[train['labels']==2]\n","km_train = train[train['labels']==3]\n","cr_train = train[train['labels']==5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZiiNnmfqfzEV","colab_type":"code","colab":{}},"cell_type":"code","source":["# largest class size is Zuma\n","class_size = train[train['labels']==4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7cpcusZlhiv6","colab_type":"text"},"cell_type":"markdown","source":["We then call the **`synthesize`** function we created, and pass to it the training data for a single president, the number of synthetic observations we would like to generate, and the range of n-values to be used for n-grams. We do this for each of the 5 presidents besides Zuma."]},{"metadata":{"id":"6PCZB4cw0QrA","colab_type":"code","colab":{}},"cell_type":"code","source":["# to what size would we like to upsample?\n","class_size = len(train[train['labels']==4])\n","\n","# run the synthesize function to generate new data for each of the presidents\n","fwdk_new = synthesize(fwdk_train, (class_size-len(fwdk_train))//2, (4,12))\n","mand_new = synthesize(mand_train, (class_size-len(mand_train))//2, (4,12))\n","mbe_new = synthesize(mbe_train, (class_size-len(mbe_train))//2, (4,12))\n","km_new = synthesize(km_train, (class_size-len(km_train))//2, (4,12))\n","cr_new = synthesize(cr_train, (class_size-len(fwdk_train))//2, (4,12))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KFKX8R9oh-kS","colab_type":"text"},"cell_type":"markdown","source":["Finally, we append the original training data set with the new synthetic data, and take a look at the new distributions across the classes."]},{"metadata":{"id":"snvdBcBf0QrC","colab_type":"code","colab":{}},"cell_type":"code","source":["# append all new data to main training data\n","train = train.append(fwdk_new).append(mand_new).append(mbe_new).append(km_new).append(cr_new)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-0sZRA-bxOOG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":389},"outputId":"ed26fff1-1a66-4729-df6f-ab44a136eb4a","executionInfo":{"status":"ok","timestamp":1537473122384,"user_tz":-120,"elapsed":1200,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["train['labels'].value_counts().plot(kind='bar')\n","plt.xlabel('Class')\n","plt.ylabel('Observations')\n","plt.title('Observations per Class')"],"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5,1,'Observations per Class')"]},"metadata":{"tags":[]},"execution_count":153},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfgAAAFjCAYAAADRiRn/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHgAAA1HwAAAYiIIHAMBA/w/EklNNCYFh/AAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f7bcd7ebda0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"PFeD1Ndyp8AC","colab_type":"text"},"cell_type":"markdown","source":["## Word tokens\n","At this stage, the data is still in text format. The next step is to 'numericalize' the data.   \n","\n","This process is known as tokenizing, which simply means to create a set of unique IDs to represent all of the words in the corpus.  \n","\n","In Python, dictionaries make this a simple task. We will need to create a dictionary to store the mapping from words to tokens.\n","\n","This can be done by creating one long array of all sentences in the corpus, and then iterating through all the words. At each consecutive word in the corpus, we will check if the word already exists in the dictionary. If the word does not exist, create an index for it. If the word is already in the dictionary, then simply skip over it.   \n","\n","As an added insight, we can keep track of how frequently words appear, by adding a second 'count' value to each word's key."]},{"metadata":{"id":"rMg8JxnkTdt0","colab_type":"text"},"cell_type":"markdown","source":["![tokens](https://github.com/James-Leslie/president-speech-classifier/blob/master/data/diagrams/tokenize.png?raw=true)"]},{"metadata":{"id":"pE5zYlgPqQix","colab_type":"code","colab":{}},"cell_type":"code","source":["# load whole corpus of words\n","all_text = df['text'].values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KoMwbnzAolbK","colab_type":"code","colab":{}},"cell_type":"code","source":["word_counts = {}\n","\n","# iterate over each sentence in the corpus\n","for text in all_text:\n","  \n","  for word in text.split():\n","    \n","    # if the word isn't in the dictionary\n","    if word not in word_counts.keys():\n","      # create a new index for it, and add 1 to its count\n","      word_counts[word] = 1\n","    \n","    # if word is already in the dictionary\n","    else:\n","      # find its key, and add 1 to its count\n","      word_counts[word] += 1\n","\n","# create mappings\n","stoi = {}  # string to index\n","itos = {}  # index to string\n","\n","idx = 1\n","\n","# order the words from most to least common\n","for word in sorted(word_counts, key=word_counts.get, reverse=True):\n","\n","    if word not in stoi.keys():\n","      stoi[word] = idx\n","      itos[idx] = word\n","      idx += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BHfGHWwjJrAq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"c372de4e-1fbf-4c66-fee5-54bb00926a65","executionInfo":{"status":"ok","timestamp":1537473125977,"user_tz":-120,"elapsed":909,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# top 25 most common words\n","sorted(word_counts, key=word_counts.get, reverse=True)[:25]"],"execution_count":156,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['the',\n"," 'of',\n"," 'to',\n"," 'and',\n"," 'in',\n"," 'we',\n"," 'our',\n"," 'that',\n"," 'a',\n"," 'will',\n"," 'this',\n"," 'as',\n"," 'for',\n"," 'is',\n"," 'have',\n"," 'with',\n"," 'are',\n"," 'on',\n"," 'be',\n"," 'all',\n"," 'government',\n"," 'by',\n"," 'year',\n"," 'it',\n"," 'south']"]},"metadata":{"tags":[]},"execution_count":156}]},{"metadata":{"id":"XhshqcgI-0DR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba14f397-648d-49c8-8d31-c6dc9ea1316b","executionInfo":{"status":"ok","timestamp":1537473127730,"user_tz":-120,"elapsed":1182,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# how many words in the corpus?\n","vocabulary_size = len(stoi.keys())\n","print(vocabulary_size)"],"execution_count":157,"outputs":[{"output_type":"stream","text":["11200\n"],"name":"stdout"}]},{"metadata":{"id":"DU6VYW7wLjTY","colab_type":"text"},"cell_type":"markdown","source":["With the dictionary created, the next step is create a tokenizer. The function below performs the task of converting a string of words into an array of tokens, using the **`stoi`** dictionary created above."]},{"metadata":{"id":"WdmayZUss8BP","colab_type":"code","colab":{}},"cell_type":"code","source":["def tokenize(string):\n","  \n","  ''' convert string to tokens '''\n","  \n","  sequence = []\n","  for word in string.split():\n","    sequence.append(stoi[word])\n","    \n","  return sequence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WFYQzsfdL5T2","colab_type":"text"},"cell_type":"markdown","source":["Similarly, we will create a function for converting from tokens back to words."]},{"metadata":{"id":"bo0OeIEdykPe","colab_type":"code","colab":{}},"cell_type":"code","source":["def untokenize(tokens):\n","  \n","  ''' convert tokens to string '''\n","  \n","  string = ' '.join(itos[token] for token in tokens)\n","  \n","  return string"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rLIETuPWMBtb","colab_type":"text"},"cell_type":"markdown","source":["#### Tokenizer example\n","The text data can now be numericalized, using the tokenizer.   \n","\n","To illustrate the concept, an arbitrary sentence is used as an example below."]},{"metadata":{"id":"1gXUEUEJxqz5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b8340e94-a8e3-4b41-9052-5b4fdb17f7ec","executionInfo":{"status":"ok","timestamp":1537473131745,"user_tz":-120,"elapsed":1025,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# view the original text data\n","train['text'][8189]"],"execution_count":160,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'we are in the midst of the first phase which is the preparatory phase which started in 2012'"]},"metadata":{"tags":[]},"execution_count":160}]},{"metadata":{"id":"OnEk9_DO1VKY","colab_type":"code","colab":{}},"cell_type":"code","source":["# tokenize the training data\n","train['tokens'] = train['text'].apply(tokenize)\n","\n","# tokenize the test data\n","test['tokens'] = test['text'].apply(tokenize)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lOlPrNQ22qOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"54843d96-9537-4dca-8d94-44fa7e68b037","executionInfo":{"status":"ok","timestamp":1537473134063,"user_tz":-120,"elapsed":934,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# show the tokenized data\n","train['tokens'][8189].values"],"execution_count":162,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([6, 17, 5, 1, 1307, 2, 1, 104, 770, 29, 14, 1, 3659, 770, 29, 472,\n","       5, 1125], dtype=object)"]},"metadata":{"tags":[]},"execution_count":162}]},{"metadata":{"id":"xAR64q1TMoPT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b3e6e92b-f5a1-4b64-b8d3-d04596781e17","executionInfo":{"status":"ok","timestamp":1537473135607,"user_tz":-120,"elapsed":897,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# convert back to text\n","untokenize(train['tokens'][8189])"],"execution_count":163,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'we are in the midst of the first phase which is the preparatory phase which started in 2012'"]},"metadata":{"tags":[]},"execution_count":163}]},{"metadata":{"id":"LnDunf4iyALI","colab_type":"code","colab":{}},"cell_type":"code","source":["# save the tokenized data as features for training\n","X_train = train['tokens'].values\n","X_test = test['tokens'].values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B0ZfUNjvNU_B","colab_type":"text"},"cell_type":"markdown","source":["## Encode category labels\n","Since we will be using a neural network to classify the sentences, we will need to convert the target column from a single value into a one-hot encoded array.   \n","\n","![encoding](https://github.com/James-Leslie/president-speech-classifier/blob/master/data/diagrams/encoding.png?raw=true)"]},{"metadata":{"id":"Jy2yl6tJ5Q0K","colab_type":"code","colab":{}},"cell_type":"code","source":["def one_hot_encode(label):\n","  \n","  # initialize zero array\n","  vec = [0, 0, 0, 0, 0, 0]\n","  \n","  # set index of array corresponding to label = 1\n","  vec[label] = 1\n","  \n","  return vec\n","\n","\n","# save encoded labels as target for model\n","y_train = np.vstack(row for row in train['labels'].apply(one_hot_encode).values)\n","y_test = np.vstack(row for row in test['labels'].apply(one_hot_encode).values)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X73YFwC4NwuM","colab_type":"text"},"cell_type":"markdown","source":["Taking a look at the output below, the labels for each observation in the data are now encoded as arrays with 6 values. The position of the 1 in the array determines the class label. The vector below corresponds to de Klerk, since he is represented by a '0' in the original data. "]},{"metadata":{"id":"bH6hPDyHNsU_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"836e7061-f292-4d69-dd37-04e5266b424b","executionInfo":{"status":"ok","timestamp":1537473139619,"user_tz":-120,"elapsed":1042,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["y_train[8189]"],"execution_count":166,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":166}]},{"metadata":{"id":"zvz8OSZv0ERO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"98cb8fe6-393e-4975-970e-7f1c65fe92af","executionInfo":{"status":"ok","timestamp":1537473140894,"user_tz":-120,"elapsed":1100,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["print('Train size:', X_train.shape)\n","print('Test size:', X_test.shape)"],"execution_count":167,"outputs":[{"output_type":"stream","text":["Train size: (11741,)\n","Test size: (1304,)\n"],"name":"stdout"}]},{"metadata":{"id":"MHyPUk-PJoIO","colab_type":"text"},"cell_type":"markdown","source":["### What does the data look like now?"]},{"metadata":{"id":"yZjFliOd2YBD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"582b62bb-ae22-408f-9276-bd11ab2401c0","executionInfo":{"status":"ok","timestamp":1537473142108,"user_tz":-120,"elapsed":1017,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["X_train"],"execution_count":168,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([list([11, 10, 600, 40, 3, 93, 66, 651, 12, 247, 19, 219, 3, 48, 8, 6, 54, 3, 237, 18, 1, 1644, 318, 2, 1, 32, 4, 1194, 2, 160, 12, 73, 12, 75, 1641, 11, 281, 85, 20, 21, 91]),\n","       list([245, 1, 139, 2, 7, 49, 10, 93, 169, 5, 1, 414, 2, 1, 56, 2764, 6, 10, 15, 3, 209, 5902, 145, 161, 2798, 161, 9456, 2, 533, 145, 442, 597, 53, 19, 1288, 5903, 4, 9457]),\n","       list([226, 40, 458, 50, 2448, 3, 118, 43, 1989, 3, 474, 9, 125, 2, 880, 120, 8, 12, 649, 1284, 1372, 4042, 3011, 15, 1905, 6, 126, 16, 1, 1744, 1245, 2, 1, 90, 122, 1128, 2688, 16, 1509, 2688]),\n","       ...,\n","       list([42, 70, 1157, 780, 640, 23, 119, 2735, 2736, 515, 21, 5619, 1288, 11106, 181, 11107, 937, 5397]),\n","       list([259, 482, 28, 3038, 287, 5623, 388, 48, 174, 167, 392, 25, 45, 6028, 1514]),\n","       list([56, 2628, 469, 106, 1743, 386, 1693, 508, 490, 589, 977, 146, 250, 351, 807, 11113, 576, 69, 21, 1768, 266, 97, 1946, 499])],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":168}]},{"metadata":{"id":"qwHHyFY1z--i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"c436d9f5-87d2-4df5-bcf7-eedc9473e965","executionInfo":{"status":"ok","timestamp":1537473143312,"user_tz":-120,"elapsed":1000,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# show a single observation\n","print('--token sequence')\n","print(X_train[325])\n","print('--words--')\n","print(untokenize(X_train[325]))\n","print('--label--')\n","print(y_train[325])"],"execution_count":169,"outputs":[{"output_type":"stream","text":["--token sequence\n","[24, 14, 9, 377, 3183, 3, 123, 207, 18, 11, 104, 83, 2, 1, 102, 123, 2, 1, 2562, 144, 726]\n","--words--\n","it is a great pleasure to address you on this first state of the nation address of the fifth democratic administration\n","--label--\n","[0 0 0 0 1 0]\n"],"name":"stdout"}]},{"metadata":{"id":"qQD4_upAz_xH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d967aad4-8113-49f2-aa1e-97061c7b7c2a","executionInfo":{"status":"ok","timestamp":1537473144821,"user_tz":-120,"elapsed":1019,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["print('Maximum train review length: {}'.format(\n","len(max(X_train, key=len))))\n","\n","print('Maximum test review length: {}'.format(\n","len(max(X_test, key=len))))"],"execution_count":170,"outputs":[{"output_type":"stream","text":["Maximum train review length: 120\n","Maximum test review length: 86\n"],"name":"stdout"}]},{"metadata":{"id":"KPNB5VljWMXW","colab_type":"text"},"cell_type":"markdown","source":["### Sentence padding\n","Lastly, before the data can be fed into any type of machine learning model, the dimensions of each observation need to be standardized.   \n","\n","In the case of a neural network, the architecture is fixed. One needs to decide beforehand, how many nodes there will be in each layer. For this reason, the sentences all need to be stretched to the same length as the longest sentence in the corpus.   \n","\n","This is done by simply padding each sentence with zeros to match the length of the longest sentence.   \n","\n","![padding](https://github.com/James-Leslie/president-speech-classifier/blob/master/data/diagrams/padding.png?raw=true)"]},{"metadata":{"id":"mHGvyO9m4NJ7","colab_type":"code","colab":{}},"cell_type":"code","source":["max_words = len(max(X_train, key=len))\n","X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n","X_test = sequence.pad_sequences(X_test, maxlen=max_words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"afKK8--nW75O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"700b8762-3bea-4ff5-947c-851c6c8ce724","executionInfo":{"status":"ok","timestamp":1537473147208,"user_tz":-120,"elapsed":1054,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# example sentence\n","X_test[1]"],"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31,\n","       217,   5,   1, 104, 931, 383, 471,   2, 146,  22, 177,   1,  42,\n","         4, 234, 215], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":172}]},{"metadata":{"id":"BZ4Tt7tbqIBb","colab_type":"text"},"cell_type":"markdown","source":["# Sentence Classifier\n","The data is now in machine-learning-ready format. The label has been one-hot encoded and all sentences have been tokenized and padded with zeros. The next step is to train some neural networks and assess their performance."]},{"metadata":{"id":"izZIpO3IqdtO","colab_type":"text"},"cell_type":"markdown","source":["## Model 1: Simple Neural Network\n","To set a benchmark, the first model to be used will be a very simple, 3-layer neural network.   \n","\n","This network takes the 120 token vector, feeds this through 3 hidden layers of 64, 32, and 16 units, each with ReLU activation functions and dropout, into a final output layer of 6 nodes which are squeezed by a softmax activation function.\n","\n","A summary of the network is given below:"]},{"metadata":{"id":"EmA8VCqQqtWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"25771c56-1a19-4633-90e2-9e8c1d0efcc2","executionInfo":{"status":"ok","timestamp":1537473148425,"user_tz":-120,"elapsed":999,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["model_1=Sequential()\n","model_1.add(Dense(64, input_dim=max_words, activation='relu'))\n","model_1.add(Dropout(0.05))\n","model_1.add(Dense(32, activation='relu'))\n","model_1.add(Dropout(0.25))\n","model_1.add(Dense(16, activation='relu'))\n","model_1.add(Dropout(0.5))\n","model_1.add(Dense(6, activation='softmax'))\n","\n","print(model_1.summary())"],"execution_count":173,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_33 (Dense)             (None, 64)                7744      \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_34 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_35 (Dense)             (None, 16)                528       \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 16)                0         \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 6)                 102       \n","=================================================================\n","Total params: 10,454\n","Trainable params: 10,454\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"qlHSPZqzYQoN","colab_type":"text"},"cell_type":"markdown","source":["The model is then trained for 10 epochs, with a batch size of 128, using a validation split of 30%.   \n","\n","After training, the model is scored against the unseen test set."]},{"metadata":{"id":"ij3bvk-arwKS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"08fe70ae-0e94-4dfa-dd24-1e80bfda8570","executionInfo":{"status":"ok","timestamp":1537473157203,"user_tz":-120,"elapsed":8653,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["batch_size = 128\n","num_epochs = 10\n","\n","model_1.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","model_1.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.3)\n","scores = model_1.evaluate(X_test, y_test)\n","print(\"\\n%s: %.2f%%\" % (model_1.metrics_names[1], scores[1]*100))"],"execution_count":174,"outputs":[{"output_type":"stream","text":["Train on 8218 samples, validate on 3523 samples\n","Epoch 1/10\n","8218/8218 [==============================] - 2s 204us/step - loss: 13.3743 - acc: 0.1533 - val_loss: 13.9057 - val_acc: 0.1354\n","Epoch 2/10\n","8218/8218 [==============================] - 1s 70us/step - loss: 12.8858 - acc: 0.1734 - val_loss: 14.0206 - val_acc: 0.1297\n","Epoch 3/10\n","8218/8218 [==============================] - 1s 69us/step - loss: 12.2539 - acc: 0.2009 - val_loss: 14.7135 - val_acc: 0.0835\n","Epoch 4/10\n","8218/8218 [==============================] - 1s 72us/step - loss: 11.6107 - acc: 0.2229 - val_loss: 14.2976 - val_acc: 0.1056\n","Epoch 5/10\n","8218/8218 [==============================] - 1s 69us/step - loss: 9.9597 - acc: 0.2574 - val_loss: 11.8386 - val_acc: 0.0749\n","Epoch 6/10\n","8218/8218 [==============================] - 1s 72us/step - loss: 6.9772 - acc: 0.2832 - val_loss: 4.9713 - val_acc: 0.0077\n","Epoch 7/10\n","8218/8218 [==============================] - 1s 69us/step - loss: 4.2678 - acc: 0.3113 - val_loss: 2.2598 - val_acc: 0.0000e+00\n","Epoch 8/10\n","8218/8218 [==============================] - 1s 72us/step - loss: 2.9145 - acc: 0.3154 - val_loss: 2.3245 - val_acc: 0.0000e+00\n","Epoch 9/10\n","8218/8218 [==============================] - 1s 68us/step - loss: 2.2419 - acc: 0.3154 - val_loss: 2.4011 - val_acc: 0.0000e+00\n","Epoch 10/10\n","8218/8218 [==============================] - 1s 71us/step - loss: 2.0122 - acc: 0.3203 - val_loss: 2.4680 - val_acc: 0.0000e+00\n","1304/1304 [==============================] - 0s 71us/step\n","\n","acc: 37.04%\n"],"name":"stdout"}]},{"metadata":{"id":"_GI_B89Ja0p0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"4d2d3261-2b6c-4216-fc66-4b0db5453d81","executionInfo":{"status":"ok","timestamp":1537473158807,"user_tz":-120,"elapsed":1543,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# calculate predictions\n","predictions_1 = model_1.predict(X_test)\n","\n","pred_lbls_1 = []\n","for pred in predictions_1:\n","  pred = list(pred)\n","  max_value = max(pred)\n","  max_index = pred.index(max_value)\n","  pred_lbls_1.append(max_index)\n","  \n","predictions_1 = np.array(pred_lbls_1)\n","\n","y_lbls = []\n","for row in y_test:\n","  row = list(row)\n","  max_value = max(row)\n","  max_index = row.index(max_value)\n","  y_lbls.append(max_index)\n","  \n","y_lbls = np.array(y_lbls)\n","\n","from sklearn.metrics import confusion_matrix\n","\n","cm_1 = confusion_matrix(y_lbls, predictions_1)\n","\n","pd.DataFrame(cm_1)"],"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>262</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>449</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>483</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  1  2  3    4  5\n","0  0  0  0  0   13  0\n","1  0  0  0  0  262  0\n","2  0  0  0  0  449  0\n","3  0  0  0  0   40  0\n","4  0  0  0  0  483  0\n","5  0  0  0  0   57  0"]},"metadata":{"tags":[]},"execution_count":175}]},{"metadata":{"id":"2KbuGFZtbMf7","colab_type":"text"},"cell_type":"markdown","source":["Taking a look at the confusion matrix above, the model is simply picking the majority class for every observation in the test set.   \n","\n","Now we will take a look at some other types of neural networks which might be better suited to the job.   \n","\n","NOTE: for each of the models shown below, a number of different architectures were trialled. The architectures shown below were those which performed the best. Of course, there is an almost infinite number of feasible architectures, and the process of model building comes down to a large amount of trial and error."]},{"metadata":{"id":"hHZL1OxYquUp","colab_type":"text"},"cell_type":"markdown","source":["## Model 2: Recurrent Neural Network (RNN) with embeddings\n","In an attempt to improve on the basic network, a recurrent neural network was attempted next. RNNs have shown themselves to be useful for the task of learning sequential data. They have been very well-used with time series data, but have also been very successfully used for NLP tasks.   \n","\n","Since sentences have order (you cannot simply swap two words around in a sentence, unlike in a data set like the Boston houses where the order of columns doesn't matter), we need to use a network which is capable of learning these patterns in data.   \n","\n","### Embeddings\n","In addition to the LSTM cell in the network, an embedding layer is used at the first layer as a way of learning semantic meaning of words, based on the context in which they will often appear."]},{"metadata":{"id":"aDaHYlAe2LHg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"8e7c2e24-89a2-411c-bfca-263619bb9f84","executionInfo":{"status":"ok","timestamp":1537475414792,"user_tz":-120,"elapsed":1262,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["embedding_size=64\n","\n","model_2=Sequential()\n","model_2.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n","model_2.add(Dropout(0.05))\n","model_2.add(Bidirectional(LSTM(64, activation='tanh')))\n","model_2.add(Dropout(0.15))\n","model_2.add(Dense(6, activation='softmax'))\n","\n","print(model_2.summary())"],"execution_count":203,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_20 (Embedding)     (None, 120, 64)           716800    \n","_________________________________________________________________\n","dropout_51 (Dropout)         (None, 120, 64)           0         \n","_________________________________________________________________\n","bidirectional_5 (Bidirection (None, 128)               66048     \n","_________________________________________________________________\n","dropout_52 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_49 (Dense)             (None, 6)                 774       \n","=================================================================\n","Total params: 783,622\n","Trainable params: 783,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"QnKfbEw_t0Mm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"7486cc22-8277-43b0-f9f7-b7eba546ca82","executionInfo":{"status":"ok","timestamp":1537475663199,"user_tz":-120,"elapsed":247187,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["batch_size = 256\n","num_epochs = 10\n","\n","model_2.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","model_2.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.3)\n","scores = model_2.evaluate(X_test, y_test)\n","print(\"\\n%s: %.2f%%\" % (model_2.metrics_names[1], scores[1]*100))"],"execution_count":204,"outputs":[{"output_type":"stream","text":["Train on 8218 samples, validate on 3523 samples\n","Epoch 1/10\n","8218/8218 [==============================] - 29s 3ms/step - loss: 1.5873 - acc: 0.3363 - val_loss: 2.8886 - val_acc: 0.0026\n","Epoch 2/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 1.2263 - acc: 0.5111 - val_loss: 2.4515 - val_acc: 0.1311\n","Epoch 3/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 1.0163 - acc: 0.5888 - val_loss: 2.5583 - val_acc: 0.1289\n","Epoch 4/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.8993 - acc: 0.6369 - val_loss: 2.4700 - val_acc: 0.1323\n","Epoch 5/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.7650 - acc: 0.6908 - val_loss: 2.2085 - val_acc: 0.1828\n","Epoch 6/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.6445 - acc: 0.7563 - val_loss: 2.0829 - val_acc: 0.2461\n","Epoch 7/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.5380 - acc: 0.8132 - val_loss: 2.3111 - val_acc: 0.2458\n","Epoch 8/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.4350 - acc: 0.8547 - val_loss: 2.0527 - val_acc: 0.2609\n","Epoch 9/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.3626 - acc: 0.8769 - val_loss: 1.9343 - val_acc: 0.2924\n","Epoch 10/10\n","8218/8218 [==============================] - 23s 3ms/step - loss: 0.2999 - acc: 0.9072 - val_loss: 1.8494 - val_acc: 0.3125\n","1304/1304 [==============================] - 6s 5ms/step\n","\n","acc: 62.96%\n"],"name":"stdout"}]},{"metadata":{"id":"MgcEjg2_k0gN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"317f926b-39f8-4c97-e2b6-3d0577c35e0e","executionInfo":{"status":"ok","timestamp":1537475698905,"user_tz":-120,"elapsed":7800,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# calculate predictions\n","predictions_2 = model_2.predict(X_test)\n","\n","pred_lbls_2 = []\n","for pred in predictions_2:\n","  pred = list(pred)\n","  max_value = max(pred)\n","  max_index = pred.index(max_value)\n","  pred_lbls_2.append(max_index)\n","  \n","predictions_2 = np.array(pred_lbls_2)\n","\n","cm_2 = confusion_matrix(y_lbls, predictions_2)\n","\n","pd.DataFrame(cm_2)"],"execution_count":205,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>116</td>\n","      <td>110</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>326</td>\n","      <td>1</td>\n","      <td>70</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>16</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>75</td>\n","      <td>4</td>\n","      <td>369</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0    1    2  3    4  5\n","0  4    2    1  4    1  1\n","1  0  116  110  2   32  2\n","2  0   51  326  1   70  1\n","3  0   10   16  1   12  1\n","4  0   28   75  4  369  7\n","5  1    7   10  0   34  5"]},"metadata":{"tags":[]},"execution_count":205}]},{"metadata":{"id":"8LoLa4Ctq1KG","colab_type":"text"},"cell_type":"markdown","source":["## Model 3: RNN with convolutional layer\n","Convolutional neural networks have also been used for NLP tasks, so this third model is an attempt at adding some additional complexity to the model.   \n","\n","The motivation for this is that the convolutional layer, in theory, would be capable of learning n-grams that appear frequently in the data set. The kernel used below is a 1x5 window which tries to learn common combinations of words."]},{"metadata":{"id":"5n-ndRFUATyH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"04320383-363b-4e86-acfb-52c50c132a36","executionInfo":{"status":"ok","timestamp":1537477420763,"user_tz":-120,"elapsed":1220,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["embedding_size=100\n","model_3=Sequential()\n","model_3.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n","model_3.add(Dropout(0.05))\n","model_3.add(Conv1D(64, 5, activation=\"relu\"))\n","model_3.add(MaxPooling1D(pool_size=4))\n","model_3.add(Bidirectional(LSTM(64, activation='tanh')))\n","model_3.add(Dropout(0.05))\n","model_3.add(Dense(6, activation='softmax'))\n","\n","print(model_3.summary())"],"execution_count":233,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_32 (Embedding)     (None, 120, 100)          1120000   \n","_________________________________________________________________\n","dropout_63 (Dropout)         (None, 120, 100)          0         \n","_________________________________________________________________\n","conv1d_37 (Conv1D)           (None, 116, 64)           32064     \n","_________________________________________________________________\n","max_pooling1d_32 (MaxPooling (None, 29, 64)            0         \n","_________________________________________________________________\n","bidirectional_11 (Bidirectio (None, 128)               66048     \n","_________________________________________________________________\n","dropout_64 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_62 (Dense)             (None, 6)                 774       \n","=================================================================\n","Total params: 1,218,886\n","Trainable params: 1,218,886\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"b3JBC0bb4qtX","colab_type":"code","colab":{}},"cell_type":"code","source":["model_3.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gan660L_47D3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"1d79adff-ef2f-4328-9f8b-2ba5fb5260ba","executionInfo":{"status":"ok","timestamp":1537477555012,"user_tz":-120,"elapsed":129031,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["batch_size = 128\n","num_epochs = 10\n","\n","model_3.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","model_3.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.3)\n","scores = model_3.evaluate(X_test, y_test)\n","print(\"\\n%s: %.2f%%\" % (model_3.metrics_names[1], scores[1]*100))"],"execution_count":235,"outputs":[{"output_type":"stream","text":["Train on 8218 samples, validate on 3523 samples\n","Epoch 1/10\n","8218/8218 [==============================] - 18s 2ms/step - loss: 1.4135 - acc: 0.4120 - val_loss: 2.4587 - val_acc: 0.1286\n","Epoch 2/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 1.0266 - acc: 0.5863 - val_loss: 2.5334 - val_acc: 0.2044\n","Epoch 3/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.7744 - acc: 0.7106 - val_loss: 2.1008 - val_acc: 0.2478\n","Epoch 4/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.5352 - acc: 0.8132 - val_loss: 1.9195 - val_acc: 0.2833\n","Epoch 5/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.3801 - acc: 0.8750 - val_loss: 2.2078 - val_acc: 0.2790\n","Epoch 6/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.2776 - acc: 0.9112 - val_loss: 2.5337 - val_acc: 0.2796\n","Epoch 7/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.2169 - acc: 0.9326 - val_loss: 2.0596 - val_acc: 0.3594\n","Epoch 8/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.1701 - acc: 0.9491 - val_loss: 2.0649 - val_acc: 0.3954\n","Epoch 9/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.1377 - acc: 0.9600 - val_loss: 2.2365 - val_acc: 0.3957\n","Epoch 10/10\n","8218/8218 [==============================] - 12s 1ms/step - loss: 0.1140 - acc: 0.9673 - val_loss: 2.2957 - val_acc: 0.4099\n","1304/1304 [==============================] - 2s 1ms/step\n","\n","acc: 57.75%\n"],"name":"stdout"}]},{"metadata":{"id":"-Ld9p--4zzHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"06360a2d-6f62-428c-f97e-7a25c96e0141","executionInfo":{"status":"ok","timestamp":1537477687999,"user_tz":-120,"elapsed":4393,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["# calculate predictions\n","predictions_3 = model_3.predict(X_test)\n","\n","pred_lbls_3 = []\n","for pred in predictions_3:\n","  pred = list(pred)\n","  max_value = max(pred)\n","  max_index = pred.index(max_value)\n","  pred_lbls_3.append(max_index)\n","  \n","predictions_3 = np.array(pred_lbls_3)\n","\n","cm_3 = confusion_matrix(y_lbls, predictions_3)\n","\n","pd.DataFrame(cm_3)"],"execution_count":236,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>129</td>\n","      <td>67</td>\n","      <td>18</td>\n","      <td>36</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>81</td>\n","      <td>267</td>\n","      <td>22</td>\n","      <td>71</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>59</td>\n","      <td>20</td>\n","      <td>334</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>23</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0    1    2   3    4   5\n","0  5    2    0   1    1   4\n","1  2  129   67  18   36  10\n","2  0   81  267  22   71   8\n","3  0    8   16   4   11   1\n","4  1   29   59  20  334  40\n","5  2    7    7   4   23  14"]},"metadata":{"tags":[]},"execution_count":236}]},{"metadata":{"id":"uIMT_MCN-yFG","colab_type":"text"},"cell_type":"markdown","source":["## Comparison of models\n","A detailed error report for each of the two models is given below.   \n","\n","For each model, the following metrics are shown:\n","  - precision: the ability of the classifier not to label a negative sample as positive $TP / (TP + FP)$   \n","  i.e. of all the positive predictions, how many were truly positive?\n","  \n","  - recall: the ability of the classifier to find all the positive samples. $TP / (TP + FN)$   \n","  i.e. of all the positive labels, how many were correctly predicted?   \n","  \n","  - f1-score: weighted average of the precision and recall. $2 \\times (precision \\times recall) / (precision + recall)$   "]},{"metadata":{"id":"MmYSJFuby-Nc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"47f1d1ab-3e10-4936-8880-18e3967c15c7","executionInfo":{"status":"ok","timestamp":1537477931136,"user_tz":-120,"elapsed":889,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["from sklearn.metrics import classification_report\n","target_names = ['de Klerk', 'Mandela', 'Mbeki', 'Motlanthe', 'Zuma', 'Ramaphosa']\n","print(classification_report(y_lbls, predictions_2, target_names=target_names))"],"execution_count":239,"outputs":[{"output_type":"stream","text":["             precision    recall  f1-score   support\n","\n","   de Klerk       0.80      0.31      0.44        13\n","    Mandela       0.54      0.44      0.49       262\n","      Mbeki       0.61      0.73      0.66       449\n","  Motlanthe       0.08      0.03      0.04        40\n","       Zuma       0.71      0.76      0.74       483\n","  Ramaphosa       0.29      0.09      0.14        57\n","\n","avg / total       0.60      0.63      0.61      1304\n","\n"],"name":"stdout"}]},{"metadata":{"id":"GzwnFCNU0PmD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"3ef7f365-acd1-4865-ec4f-2da47794bed5","executionInfo":{"status":"ok","timestamp":1537477847343,"user_tz":-120,"elapsed":870,"user":{"displayName":"James Leslie","photoUrl":"//lh3.googleusercontent.com/-Z1vsNe-yMBg/AAAAAAAAAAI/AAAAAAAAKBA/jpjYU4ZmV14/s50-c-k-no/photo.jpg","userId":"116634141730498852088"}}},"cell_type":"code","source":["from sklearn.metrics import classification_report\n","target_names = ['de Klerk', 'Mandela', 'Mbeki', 'Motlanthe', 'Zuma', 'Ramaphosa']\n","print(classification_report(y_lbls, predictions_3, target_names=target_names))"],"execution_count":238,"outputs":[{"output_type":"stream","text":["             precision    recall  f1-score   support\n","\n","   de Klerk       0.50      0.38      0.43        13\n","    Mandela       0.50      0.49      0.50       262\n","      Mbeki       0.64      0.59      0.62       449\n","  Motlanthe       0.06      0.10      0.07        40\n","       Zuma       0.70      0.69      0.70       483\n","  Ramaphosa       0.18      0.25      0.21        57\n","\n","avg / total       0.60      0.58      0.59      1304\n","\n"],"name":"stdout"}]},{"metadata":{"id":"_-PzCFF30iV3","colab_type":"text"},"cell_type":"markdown","source":["### Analysis\n","Of the two models, the plain RNN model has the higher overall f1 score and accuracy. Interestingly though, the RNN/CNN model consistently outperformed the RNN in terms of recall on the smaller classes.\n","\n","## Further improvements\n","\n","#### 1. Class imbalance\n","Undoubtedly, the main area for concern with this data set is the class imbalance. We attempted to generate additional sentences for the minority classes, but the resulting sythetic sentences were not very similar to real English sentences in the end.\n","\n","#### 2. Ensemble model\n","An alternative method for performing the classifications could be to leverage the respective strengths of each of the two models in a type of ensemble model. The plain RNN showed that it performed better on the majority classes, while the RNN/CNN performed better on the minority classes.   \n","\n","One solution could be to train the RNN to classify Zuma vs Mbeki vs \"Other\", and to then pass the \"Other\" predictions on to the RNN/CNN model."]}]}